{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"7\"> Modeling </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataframe\", keep_default_na = False, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>media_only</th>\n",
       "      <th>permalink</th>\n",
       "      <th>textsum</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gorgeous NASA X-ray images of universe look li...</td>\n",
       "      <td>1602008143</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>Sorin61</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j6aaro/gorgeous_nasa_...</td>\n",
       "      <td>Gorgeous NASA X-ray images of universe look li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can someone please explain how to calculate th...</td>\n",
       "      <td>1602006466</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>astrojosue</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j69qx5/can_someone_pl...</td>\n",
       "      <td>Can someone please explain how to calculate th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can someone explain formula to calculate the m...</td>\n",
       "      <td>1602000784</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>astrojosue</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j67wz2/can_someone_ex...</td>\n",
       "      <td>Can someone explain formula to calculate the m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can someone elaborate?</td>\n",
       "      <td>1601999794</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>astrojosue</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j67lw5/can_someone_el...</td>\n",
       "      <td>Can someone elaborate?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maybe astrophysics is not for me! Just watched...</td>\n",
       "      <td>1601987660</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>Yugitonii</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j6485v/maybe_astrophy...</td>\n",
       "      <td>Maybe astrophysics is not for me! Just watched...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Extended essay</td>\n",
       "      <td>1601966026</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>annawithann</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j608lt/extended_essay/</td>\n",
       "      <td>Extended essay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extended essay</td>\n",
       "      <td>1601965817</td>\n",
       "      <td>Hello everyone! I'm a high school student, and...</td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>MartynaLaptev</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j6079j/extended_essay/</td>\n",
       "      <td>Extended essay Hello everyone! I'm a high scho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>One of the strangest objects in space may be k...</td>\n",
       "      <td>1601956254</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>microworlds</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j5y9hv/one_of_the_str...</td>\n",
       "      <td>One of the strangest objects in space may be k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Any worthwhile certificates?</td>\n",
       "      <td>1601955078</td>\n",
       "      <td>I have a bachelors in IT and am hoping to purs...</td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>brain____dead</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j5xzpz/any_worthwhile...</td>\n",
       "      <td>Any worthwhile certificates? I have a bachelor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are your thoughts on Gravitons being used...</td>\n",
       "      <td>1601954472</td>\n",
       "      <td></td>\n",
       "      <td>astrophysics</td>\n",
       "      <td>TheScienceVerse</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/astrophysics/comments/j5xunw/what_are_your_...</td>\n",
       "      <td>What are your thoughts on Gravitons being used...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  created_utc  \\\n",
       "0  Gorgeous NASA X-ray images of universe look li...   1602008143   \n",
       "1  Can someone please explain how to calculate th...   1602006466   \n",
       "2  Can someone explain formula to calculate the m...   1602000784   \n",
       "3                             Can someone elaborate?   1601999794   \n",
       "4  Maybe astrophysics is not for me! Just watched...   1601987660   \n",
       "5                                     Extended essay   1601966026   \n",
       "6                                     Extended essay   1601965817   \n",
       "7  One of the strangest objects in space may be k...   1601956254   \n",
       "8                       Any worthwhile certificates?   1601955078   \n",
       "9  What are your thoughts on Gravitons being used...   1601954472   \n",
       "\n",
       "                                            selftext     subreddit  \\\n",
       "0                                                     astrophysics   \n",
       "1                                                     astrophysics   \n",
       "2                                                     astrophysics   \n",
       "3                                                     astrophysics   \n",
       "4                                                     astrophysics   \n",
       "5                                                     astrophysics   \n",
       "6  Hello everyone! I'm a high school student, and...  astrophysics   \n",
       "7                                                     astrophysics   \n",
       "8  I have a bachelors in IT and am hoping to purs...  astrophysics   \n",
       "9                                                     astrophysics   \n",
       "\n",
       "            author  media_only  \\\n",
       "0          Sorin61       False   \n",
       "1       astrojosue       False   \n",
       "2       astrojosue       False   \n",
       "3       astrojosue       False   \n",
       "4        Yugitonii       False   \n",
       "5      annawithann       False   \n",
       "6    MartynaLaptev       False   \n",
       "7      microworlds       False   \n",
       "8    brain____dead       False   \n",
       "9  TheScienceVerse       False   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/astrophysics/comments/j6aaro/gorgeous_nasa_...   \n",
       "1  /r/astrophysics/comments/j69qx5/can_someone_pl...   \n",
       "2  /r/astrophysics/comments/j67wz2/can_someone_ex...   \n",
       "3  /r/astrophysics/comments/j67lw5/can_someone_el...   \n",
       "4  /r/astrophysics/comments/j6485v/maybe_astrophy...   \n",
       "5    /r/astrophysics/comments/j608lt/extended_essay/   \n",
       "6    /r/astrophysics/comments/j6079j/extended_essay/   \n",
       "7  /r/astrophysics/comments/j5y9hv/one_of_the_str...   \n",
       "8  /r/astrophysics/comments/j5xzpz/any_worthwhile...   \n",
       "9  /r/astrophysics/comments/j5xunw/what_are_your_...   \n",
       "\n",
       "                                             textsum  0  \n",
       "0  Gorgeous NASA X-ray images of universe look li...  0  \n",
       "1  Can someone please explain how to calculate th...  0  \n",
       "2  Can someone explain formula to calculate the m...  0  \n",
       "3                            Can someone elaborate?   0  \n",
       "4  Maybe astrophysics is not for me! Just watched...  0  \n",
       "5                                    Extended essay   0  \n",
       "6  Extended essay Hello everyone! I'm a high scho...  0  \n",
       "7  One of the strangest objects in space may be k...  0  \n",
       "8  Any worthwhile certificates? I have a bachelor...  0  \n",
       "9  What are your thoughts on Gravitons being used...  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10) #output first ten rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"0\": \"category\"}, inplace = True) # change column name of binary class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"title\"] # assign feature space\n",
    "y = df[\"category\"] #assign target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=60, stratify=y) # split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(stop_words = \"english\") #instantiate CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=300) #Instantiate Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(cvect, lr) # make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('logisticregression', LogisticRegression(max_iter=300))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train) # fit pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a sizeable discrepancy between the score on training data and testing data. The score of 0.768 is certainly better than 0.5 ( randomly choosing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"textsum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(stop_words = \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('logisticregression', LogisticRegression(max_iter=300))])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986666666666667"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performed better when using the sum of the title and selftext columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2.677758</td>\n",
       "      <td>particle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>1.269378</td>\n",
       "      <td>cern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>1.189057</td>\n",
       "      <td>quantum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.987254</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>0.980944</td>\n",
       "      <td>standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>0.970078</td>\n",
       "      <td>higgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>0.916095</td>\n",
       "      <td>youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.909031</td>\n",
       "      <td>particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.901550</td>\n",
       "      <td>antimatter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>0.823442</td>\n",
       "      <td>spin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.817381</td>\n",
       "      <td>matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>0.765505</td>\n",
       "      <td>photon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>0.762149</td>\n",
       "      <td>hep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>0.743030</td>\n",
       "      <td>proton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.742887</td>\n",
       "      <td>collider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs        word\n",
       "1456  2.677758    particle\n",
       "358   1.269378        cern\n",
       "1602  1.189057     quantum\n",
       "2106  0.987254       using\n",
       "1876  0.980944    standard\n",
       "980   0.970078       higgs\n",
       "2209  0.916095     youtube\n",
       "1458  0.909031   particles\n",
       "142   0.901550  antimatter\n",
       "1861  0.823442        spin\n",
       "1257  0.817381      matter\n",
       "1489  0.765505      photon\n",
       "974   0.762149         hep\n",
       "1581  0.743030      proton\n",
       "430   0.742887    collider"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefs = pipe.named_steps[\"logisticregression\"].coef_[0] #\n",
    "\n",
    "words = pipe.named_steps['countvectorizer'].get_feature_names()\n",
    "\n",
    "word_def = pd.DataFrame({'coefs': word_coefs, 'word': words})\n",
    "\n",
    "word_def.nlargest(15, 'coefs')\n",
    "\n",
    "#output 15  most signifcant words in accordance with coefficents \n",
    "#the higher the coefficent the more it contributed to the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_in(transformer, estimator):\n",
    "    pipe = make_pipeline(transformer, estimator)\n",
    "    return pipe\n",
    "\n",
    "def parameters(transformer):\n",
    "    adjust = (str(transformer).replace('()', \"\")).lower()\n",
    "    params = { adjust + '__max_features': [100, 500], adjust + '__stop_words': ['english', None], adjust + '__ngram_range': [(1, 1), (1, 2), (1, 3)]}\n",
    "    return params\n",
    "\n",
    "\n",
    "def gridsearch(transformer, estimator):\n",
    "\n",
    "    pipe = pipe_in(transformer, estimator)\n",
    "    params = parameters(transformer)\n",
    "    gs = GridSearchCV(pipe,\n",
    "                      param_grid=params,\n",
    "                      cv=7,\n",
    "                      n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_model = gs.best_estimator_\n",
    "    \n",
    "  \n",
    "    print('Best model:', gs.best_params_)\n",
    "    print('Best model:', best_model)\n",
    "    print('Best model Score:', gs.best_score_)\n",
    "    print('Training data Score:', best_model.score(X_train, y_train))\n",
    "    print('Testing Data Score:', best_model.score(X_test, y_test))\n",
    "#establish a gridsearch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'countvectorizer__max_features': 500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english'}\n",
      "Best model: Pipeline(steps=[('countvectorizer',\n",
      "                 CountVectorizer(max_features=500, stop_words='english')),\n",
      "                ('logisticregression', LogisticRegression(max_iter=400))])\n",
      "Best model Score: 0.8293333333333333\n",
      "Training data Score: 0.94\n",
      "Testing Data Score: 0.764\n"
     ]
    }
   ],
   "source": [
    "gridsearch(CountVectorizer(), LogisticRegression(max_iter=400)) #gridsearch for logistic regression and countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "Best model: {'countvectorizer__max_features': 500, 'countvectorizer__ngram_range': (1, 1), 'countvectorizer__stop_words': 'english'}\n",
      "\n",
      "Best model: Pipeline(steps=[('countvectorizer',\n",
      "                 CountVectorizer(max_features=500, stop_words='english')),\n",
      "                ('multinomialnb', MultinomialNB())])\n",
      "\n",
      "Cross-val score of the best model: 0.7666666666666667\n",
      "Accuracy of best model on the training data: 0.8706666666666667\n",
      "Accuracy of best model on the testing data: 0.736\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gridsearch(CountVectorizer(), MultinomialNB()) # gridsearch with multinomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer\n",
      "Best model: {'countvectorizer__max_features': 400, 'countvectorizer__ngram_range': (1, 4), 'countvectorizer__stop_words': None}\n",
      "\n",
      "Best model: Pipeline(steps=[('countvectorizer',\n",
      "                 CountVectorizer(max_features=400, ngram_range=(1, 4))),\n",
      "                ('adaboostclassifier', AdaBoostClassifier())])\n",
      "\n",
      "Cross-val score of the best model: 0.772\n",
      "Accuracy of best model on the training data: 0.8573333333333333\n",
      "Accuracy of best model on the testing data: 0.748\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gridsearch(CountVectorizer(), AdaBoostClassifier()) #adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "toke = RegexpTokenizer('\\w+') # establish tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmat = WordNetLemmatizer() #establish lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lemmatize(column):\n",
    "    list_of_tokens = []\n",
    "    for string in column:\n",
    "        list_of_tokens.append(toke.tokenize(string))\n",
    "    e =  list_of_tokens\n",
    "    \n",
    "    list_of_lemmas = []\n",
    "    for token in e:\n",
    "        list_of_lemmas.append(lemmat.lemmatize(str(token)))\n",
    "    return list_of_lemmas   \n",
    "\n",
    "# establish a function that tokenize and lemmatizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenize_lemmatize(X_train)\n",
    "X_test = tokenize_lemmatize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'tfidfvectorizer__max_features': 500, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n",
      "Best model: Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(max_features=500, stop_words='english')),\n",
      "                ('logisticregression', LogisticRegression())])\n",
      "Best model Score: 0.8453333333333333\n",
      "Training data Score: 0.936\n",
      "Testing Data Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "gridsearch(TfidfVectorizer(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "port = PorterStemmer() #use a porter stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_porter(column):\n",
    "    list_of_tokens = []\n",
    "    for string in column:\n",
    "        list_of_tokens.append(toke.tokenize(string))\n",
    "    e =  list_of_tokens\n",
    "\n",
    "    list_of_stems = []\n",
    "    for string in e:\n",
    "        list_of_stems.append(port.stem(str(string)))\n",
    "    return list_of_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenize_porter(X_train)\n",
    "X_test = tokenize_porter(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'tfidfvectorizer__max_features': 500, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n",
      "Best model: Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(max_features=500, stop_words='english')),\n",
      "                ('logisticregression', LogisticRegression(C=1.1))])\n",
      "Best model Score: 0.8453333333333333\n",
      "Training data Score: 0.936\n",
      "Testing Data Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "gridsearch(TfidfVectorizer(), LogisticRegression()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = RandomForestClassifier(max_depth=2, random_state=0) # random forests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'tfidfvectorizer__max_features': 500, 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__stop_words': 'english'}\n",
      "Best model: Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(max_features=500, stop_words='english')),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=6))])\n",
      "Best model Score: 0.7813333333333333\n",
      "Training data Score: 0.84\n",
      "Testing Data Score: 0.716\n"
     ]
    }
   ],
   "source": [
    "gridsearch(TfidfVectorizer(), RandomForestClassifier(max_depth=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier # stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: {'tfidfvectorizer__max_features': 500, 'tfidfvectorizer__ngram_range': (1, 3), 'tfidfvectorizer__stop_words': 'english'}\n",
      "Best model: Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(max_features=500, ngram_range=(1, 3),\n",
      "                                 stop_words='english')),\n",
      "                ('sgdclassifier', SGDClassifier(max_iter=5))])\n",
      "Best model Score: 0.8280000000000001\n",
      "Training data Score: 0.968\n",
      "Testing Data Score: 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiffraw/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "gridsearch(TfidfVectorizer(), SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch(TfidfVectorizer(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer(max_features=500)),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(max_features=500),\n",
    "                          LogisticRegression())\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105,  20],\n",
       "       [ 35,  90]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = best_pipe.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, preds)\n",
    "conf_matrix\n",
    "#Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = conf_matrix.ravel() # True negative, False positive, false negative, True positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted Astrophysics</th>\n",
       "      <th>predicted Particle Physics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual Astrophysics</th>\n",
       "      <td>105</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual Particle Physics</th>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         predicted Astrophysics  predicted Particle Physics\n",
       "actual Astrophysics                         105                          20\n",
       "actual Particle Physics                      35                          90"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(conf_matrix, index=['actual Astrophysics', 'actual Particle Physics'], \n",
    "                 columns=['predicted Astrophysics', 'predicted Particle Physics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was logistic regression coupled with Tfidf.  It acquired an accuracy of 0.82.  The underlying limitations of this project was that only 500 posts were utilized for both the Astrophysics and Particle Physics Reddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
